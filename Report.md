# Abstract
### Ideas, bits and parts

How do you differenciate a cell from a simple circle ? Answering such question sounds trivial at first glance: you can tell visually and from your experience. However, when trying to implement such decision in a computer program the question complexifies. 

With the increasing amount of data generated by biology experiment

Classification and segmentation is a good example for machine learning usezfullness. How do you differenciate a cell from a simple round and how do you scale up your answer without increasing exponentially the time of analysis ?

### Abstract v1
Computer sciences has become a pivotal discipline when approaching biological problems. Indeed, a majority of questions in biology requires the use of big and complex datasets. Hence, the ability to treat these data is crucial. Machine learning provides in that sense a powerfull tool for such problems. Machine learning relies on the principle that a program can "learn" to recognize specific patterns and can thus predict an output from an input. Such tool is extremely useful in image analysis as it enables a large scale and fast analysis. Indeed a major problem in image analysis is segmentation, the ability to distinguish between to separate region. In this report we report a method for quantifying the ability of machine learnng to perform segmentation on images. We discuss different metrics that can be use to supervise such process and we propose a method to compare different network architectures and outputs.

**Key-words:** Machine learning, segmentation, quantification, ...

### Abstract v2

Computer sciences has become a pivotal discipline when approaching biological problems. In microscopy for instance, the instruments and the growing scalability of the experiments has lead the data analysis process to be computer dependent. In the recent years machine learning approaches have been proven to be a powerfull tool for analysis. Machine learning relies on the principle that a program can "learn" to recognize specific patterns and can thus predict an output from an input. A classical problem in image analysis is segmentation, how do you set rules for determining boundaries in data. Fortunatly, such problem is commonly encountered in computer sciences and many techniques have been developped. In this report we report a method for quantifying the ability of machine learnng to perform segmentation on images. We discuss different metrics that can be use to supervise such process and we propose a method to compare different network architectures and outputs.

**Key-words:** Machine learning, segmentation, quantification, ...

### Abstract v3 

#### Evaluating machine learning performance : development of quantification protocol to evaluate AI segmentation algorithms

A.Kanso $*$ , N.Louafi  , M.Nollman**

$*$ Corresponding author: [kanso.ali@outlook.fr](mailto:kanso.ali@outlook.fr) 

** Project Supervisor: [marcelo.nollmann@cbs.cnrs.fr](mailto:marcelo.nollmann@cbs.cnrs.fr) 

Computer science has become a pivotal discipline when approaching biological problems. In microscopy for instance, the instruments and the growing scalability of the experiments have led the data analysis process to be computer dependent. Machine learning, as it has been proven recently to be a powerful tool for analysis, relies on the concept that a program can learn from data, and thus recognize specific patterns and make decisions to predict an output. When talking about image analysis, the fact that we must set rules for determining boundaries in data, makes image segmentation a major problem.Fortunately, such problem is commonly encountered in computer sciences and many techniques have been developed. In this report we introduce a method that quantifies the "accuracy" of machine learning in performing image segmentation and we discuss different metrics that can be used to supervise such process. We also propose a method to compare different network architectures and outputs.

# Introduction
**Topics to introduce**

- How computer sciences help biology
- Introduce the concept of neural networks
- Segmentation 
- How there are no real way of quantifying a network performance
- We used both qualitative (gallery) and quantitative approaches
- Figure that represents the worflow of the method developped
- Why is it important to automatize the segmentation (see Lab1 description)
- What the images will be used for ? 
- Introdue the problematic of we suspect a tendency to miss bright objects 

[[figures#Figure 1]]



# Methods


Maybe methods could be something like a lexique ? where we define technical terms used ?:
- Neural network
- Training and validation
- epoch 
- loss function
- segmentation 
- ... 

# Results
### Qualitative approach to network performance
Questions the paragraph is trying to anwser :

Intuitive approach : what does the segmented objects look like ?
Are they all real ? 
Does the network detects background ? if so is it because it is high intensity ?

[[figures#Figure 2]]
Responses :

The network seems to segment low intensity objects but also background of high intensity 


### Quantitative approach to network performance

[[figures#Figure 3]]

Can we put numbers on qualitative observation we made earlier ? 
Describe each metrics and why do we put it there 


### Further study on intensity sensitivity

To study the dependency to intensity of the segmentation we decided to compare our neural network approach to an intensity based segmentation. The Starfind algorithm (inserer ref) was originally developed to segment images of the sky to find bright spots which corresponded to stars. The segmentation is thus done through an intensity thresholding which can be adapted. We decided to compare the result of a Starfind segmentation and our neural network. To qualitatively evaluate such comparison we decided to develop an *accuracy* metric, that is, a ratio between the number of object detected by both method divided by the number of object detected by the Starfind algorithm. This metric will thus yield higher value for images where all the high intensity objects were detected by the neural network. To ensure that Starfind did in fact segment high intensity object we set the threshold parameters accordingly. Practically, the accuracy was computed by transposing the coordinate of the detected objects by Starfind onto the output of the network. As shown in figure X not all the bright objects were segmented by the network. This conclusion confirmed earlier visual observation that bright objects tends to be "missed". In biological context bright object correspond to fluorescent molecules which are of interest for later analysis. 

Considering the importance of bright fluorescent events we focused on finding a way to get rid of these missed events. To do so, we decided to play on the training of the network. The neural network is trained using a set of images and tries to generalize to be able to be used on a variety of images. Thus we decided to design a method to automatically correct sets of images that could be then used to train the network. The method relies on the accuracy measurement described above. When an object is only detected by Starfind, we virtually added an object in the image. The object added corresponds to a standard sphere picked in a random image. Knowingly, we introduce a bias at this step as the corrected image will all have the same correction. However, theoretically when fed to the network the images will be more complete meaning a better learning.  


[[figures#Figure 4]]

The network was given 500 epochs of 100 steps. Figure XX shows the learning curve i.e : the evolution of the error function per learning iteration. We see that the training was succesfull as the error is decreasing. To evaluate quantitatively the training one can also look at the number of true positive, true negative, false positive and false negative that are shown in annex 1. We see that the number of true positive is high which means good specificity and the number of false negative is low which indicates high sensitivity. However, these metrics only give information on the training itself that is we comparing the network performance on known image. To evaluate the quality of the training and thus the performance of the network we performed a segmentation with the new network on a never-seen image that yielded the results shown in figure XX.

[[figures#Figure 8]] , [[figures#Figure 6]]

We compared the results with the first network we worked with, described above. We observe that as the objectdetected seem coherent (pannel A) we observe a loss of the low intensity objects . Moreover, the amount of detection has decreased as well as the volume distribution. These results were not the expected ones.  

### Correcting a network 
Introduce the concept of network training, trainin vs testing dataset , ground truth ?
Introduce the concept of the correction :
- Compare starfind stardist 
- if not the same add a template sphere in the image
- why did we chose this template sphere ?
- cut the image
- relabel the image
- save only the corrected subimages
### Retraining effects
Discuss the improvement of the training if there was 


Probably not all the plots but maybe a combination if the concepts were introduced before ? 

# Discussion 


Figure X:  General workflow of the lab1

- discuss the fact that low intensity object were not corrected for ?
- optimizatyion of the code to work faster 
- optimization of thye code to work on bigger image without surcharging the GPU 
- necessity for such analysis , relevance of needing a corrction for 20% of the opbjects ? 

# Annex

[[figures#Figure 9]]

# References 
**Stardist :**
Schmidt, U., Weigert, M., Broaddus, C., & Myers, G. (2018). Cell Detection with Star-Convex Polygons. In A. F. Frangi, J. A. Schnabel, C. Davatzikos, C. Alberola-López, & G. Fichtinger (Éds.), _Medical Image Computing and Computer Assisted Intervention – MICCAI 2018_ (Vol. 11071, p. 265‑273). Springer International Publishing. [https://doi.org/10.1007/978-3-030-00934-2_30](https://doi.org/10.1007/978-3-030-00934-2_30)

**Machine learning reviews :**

Greener, J. G., Kandathil, S. M., Moffat, L., & Jones, D. T. (2022). A guide to machine learning for biologists. _Nature Reviews Molecular Cell Biology_, _23_(1), 40‑55. [https://doi.org/10.1038/s41580-021-00407-0](https://doi.org/10.1038/s41580-021-00407-0)

Moen, E., Bannon, D., Kudo, T., Graf, W., Covert, M., & Van Valen, D. (2019). Deep learning for cellular image analysis. _Nature Methods_, _16_(12), 1233‑1246. [https://doi.org/10.1038/s41592-019-0403-1](https://doi.org/10.1038/s41592-019-0403-1)

von Chamier, L., Laine, R. F., & Henriques, R. (2019). Artificial intelligence for microscopy : What you should know. _Biochemical Society Transactions_, _47_(4), 1029‑1040. [https://doi.org/10.1042/BST20180391](https://doi.org/10.1042/BST20180391)

**pyHiM:**

Cardozo Gizzi, A. M., Cattoni, D. I., Fiche, J.-B., Espinola, S. M., Gurgo, J., Messina, O., Houbron, C., Ogiyama, Y., Papadopoulos, G. L., Cavalli, G., Lagha, M., & Nollmann, M. (2019). Microscopy-Based Chromosome Conformation Capture Enables Simultaneous Visualization of Genome Organization and Transcription in Intact Organisms. _Molecular Cell_, _74_(1), 212-222.e5. [https://doi.org/10.1016/j.molcel.2019.01.011](https://doi.org/10.1016/j.molcel.2019.01.011)

Espinola, S. M., Götz, M., Bellec, M., Messina, O., Fiche, J.-B., Houbron, C., Dejean, M., Reim, I., Cardozo Gizzi, A. M., Lagha, M., & Nollmann, M. (2021). Cis-regulatory chromatin loops arise before TADs and gene activation, and are independent of cell fate during early Drosophila development. _Nature Genetics_, _53_(4), 477‑486. [https://doi.org/10.1038/s41588-021-00816-z](https://doi.org/10.1038/s41588-021-00816-z)
**Stardist**

Larry Bradley, Brigitta Sipőcz, Thomas Robitaille, Erik Tollerud, Zé Vinícius, Christoph Deil, Kyle Barbary, Tom J Wilson, Ivo Busko, Axel Donath, Hans Moritz Günther, Mihai Cara, P. L. Lim, Sebastian Meßlinger, Simon Conseil, Azalee Bostroem, Michael Droettboom, E. M. Bray, Lars Andersen Bratholm, … Harrison Souchereau. (2022). astropy/photutils: (1.4.0). Zenodo. [https://doi.org/10.5281/zenodo.6385735](https://doi.org/10.5281/zenodo.6385735)


# Plots



